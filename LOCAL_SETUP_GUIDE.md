# ğŸš€ Local-Only ML Pipeline Setup Guide

**S3 DISABLED** - Your ML pipeline now runs completely locally without AWS dependencies!

## ğŸ¯ What's Changed

### âœ… **Local File Storage**
- âŒ **No AWS S3** - Files stored locally in `./storage/` directory
- âŒ **No AWS Credentials** - No need for AWS account or API keys
- âŒ **No Internet** - Works completely offline (except for Claude API)
- âœ… **Simple Setup** - Just run and go!

### ğŸ”§ **Storage Structure**
```
storage/
â”œâ”€â”€ uploads/           # Original CSV files
â”œâ”€â”€ processed/         # Cleaned/processed CSV files
â””â”€â”€ models/           # Trained ML models (future)
```

---

## ğŸš§ Simplified Setup Requirements

### 1. Environment Variables (.env file)
```bash
# Flask Configuration
FLASK_ENV=development
PORT=5003

# API Keys - REPLACE WITH YOUR ACTUAL KEYS
ANTHROPIC_API_KEY=your_actual_anthropic_key  # Get from: https://console.anthropic.com/
E2B_API_KEY=your_actual_e2b_key              # Get from: https://e2b.dev/

# Local Storage Configuration
STORAGE_ROOT=./storage
UPLOAD_FOLDER=/tmp/uploads
MAX_CONTENT_LENGTH=52428800
```

### 2. Backend Dependencies (AWS Removed)
```bash
cd backend
pip install -r requirements.txt
```

**No longer includes:**
- âŒ `boto3` - AWS SDK
- âŒ `botocore` - AWS core library
- âœ… All ML libraries still included

### 3. Frontend Dependencies (Unchanged)
```bash
cd frontend
npm install
```

---

## ğŸ”‘ API Key Setup (Only 2 Keys Needed)

### Claude API (Required for Code Generation)
1. Visit https://console.anthropic.com/
2. Create account and get API key
3. Add to `.env`: `ANTHROPIC_API_KEY=your_key_here`

### E2B API (Required for Code Execution)
1. Visit https://e2b.dev/
2. Sign up and create API key
3. Add to `.env`: `E2B_API_KEY=your_key_here`

### âŒ AWS Setup Not Needed
- No S3 bucket creation
- No IAM user creation
- No AWS credentials
- No internet dependency for storage

---

## ğŸš€ Starting the Application

### 1. Backend (Terminal 1)
```bash
cd backend
python run.py
```
**Expected output:**
- âœ… Flask server starting on port 5003
- âœ… Local storage initialized at `./storage/`
- âœ… Claude API health check: OK
- âœ… E2B sandbox health check: OK
- âŒ No S3 connection needed

### 2. Frontend (Terminal 2)
```bash
cd frontend
npm run dev
```
**Expected output:**
- âœ… Vite dev server on http://localhost:5173
- âœ… React app with ML Pipeline Wizard
- âœ… Local storage integration

---

## ğŸ§ª Testing the Complete Pipeline

### Phase 1: Local Upload & Analysis
1. **Upload CSV**: Drag and drop any CSV file
   - Files stored in `./storage/uploads/`
   - Instant local access, no cloud upload
2. **Select Target**: Choose the column to predict
3. **View Analysis**: See comprehensive dataset insights

### Phase 2: Local Code Generation & Execution
4. **Generate Code**: Claude creates preprocessing code
5. **Execute Code**: E2B sandbox runs the code securely
6. **Download Results**: Get cleaned CSV from `./storage/processed/`

### Phase 3: Local Multi-Model Training
7. **Generate Training**: Claude creates training code
8. **Train Models**: 4 models train using local data
9. **View Results**: Compare performance on leaderboard
10. **Download Models**: Save trained models locally

### Health Check Endpoints
```bash
# Local storage health (NEW)
curl http://localhost:5003/api/storage/health

# Storage statistics (NEW)
curl http://localhost:5003/api/storage/stats

# Claude API health
curl http://localhost:5003/api/claude/health

# E2B sandbox health
curl http://localhost:5003/api/e2b/health
```

---

## ğŸ“ File Management

### Local Storage Benefits
- **Instant Access**: No network latency
- **No Costs**: No cloud storage fees
- **Privacy**: Data never leaves your machine
- **Offline Work**: No internet needed for file operations
- **Simple Backup**: Just copy the `storage/` folder

### File Locations
```bash
# Original uploads
./storage/uploads/20241214_143052_a1b2c3d4_data.csv

# Processed data
./storage/processed/20241214_143052_a1b2c3d4_cleaned_data.csv

# Check storage usage
curl http://localhost:5003/api/storage/stats
```

### Cleaning Up Old Files
```bash
# The system automatically manages storage
# Files are organized by timestamp for easy cleanup
# You can manually delete old files from ./storage/ directory
```

---

## ğŸ› ï¸ Development Workflow

### Updated File Structure
```
backend/
â”œâ”€â”€ app/services/
â”‚   â”œâ”€â”€ local_storage_service.py  # âœ¨ LOCAL storage (replaces S3)
â”‚   â”œâ”€â”€ claude_service.py         # âœ… AI code generation
â”‚   â”œâ”€â”€ e2b_service.py           # âœ… Sandbox execution
â”‚   â”œâ”€â”€ data_analysis_service.py  # âœ… Dataset analysis
â”‚   â””â”€â”€ preprocessing_service.py  # âœ… Legacy preprocessing
â”œâ”€â”€ storage/                      # âœ¨ LOCAL file storage
â”‚   â”œâ”€â”€ uploads/                  # Original files
â”‚   â”œâ”€â”€ processed/                # Cleaned files
â”‚   â””â”€â”€ models/                   # ML models
â””â”€â”€ requirements.txt              # âœ… AWS dependencies removed

frontend/src/
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ MLPipelineWizard.tsx     # âœ… Updated for local storage
â”‚   â”œâ”€â”€ DataAnalysis.tsx         # âœ… storageKey instead of s3Key
â”‚   â”œâ”€â”€ PreprocessingStep.tsx    # âœ… Local file handling
â”‚   â”œâ”€â”€ ModelTraining.tsx        # âœ… Local storage integration
â”‚   â””â”€â”€ [other components]       # âœ… All updated
â””â”€â”€ types/index.ts               # âœ… storage_key instead of s3_key
```

### New API Endpoints
- âœ… `/api/storage/health` - Local storage health check
- âœ… `/api/storage/stats` - Storage usage statistics
- âœ… `/api/download-local/<key>` - Direct local file download
- âœ… All existing endpoints now use `storage_key` instead of `s3_key`

---

## ğŸš¨ Troubleshooting (Simplified)

### Common Issues

#### 1. "Storage Directory Error"
- âœ… Check that `./storage/` directory exists
- âœ… Ensure write permissions: `chmod 755 ./storage`
- âœ… Check `STORAGE_ROOT` in `.env`

#### 2. "File Not Found"
- âœ… Verify files in `./storage/uploads/`
- âœ… Check file permissions
- âœ… Ensure no special characters in filenames

#### 3. "Claude API Error" (Same as before)
- âœ… Check `ANTHROPIC_API_KEY` in `.env`
- âœ… Verify API key at https://console.anthropic.com/

#### 4. "E2B Sandbox Failed" (Same as before)
- âœ… Check `E2B_API_KEY` in `.env`
- âœ… Verify account at https://e2b.dev/

#### âŒ No AWS Issues to Troubleshoot!
- No S3 access denied errors
- No IAM permission problems
- No AWS credential issues
- No internet connectivity problems

### Debug Commands
```bash
# Test local storage
curl -X GET http://localhost:5003/api/storage/health

# Check storage usage
curl -X GET http://localhost:5003/api/storage/stats

# List uploaded files
ls -la ./storage/uploads/

# Check storage permissions
ls -ld ./storage/

# Test Claude API (same as before)
curl -X GET http://localhost:5003/api/claude/health

# Test E2B sandbox (same as before)
curl -X GET http://localhost:5003/api/e2b/health
```

---

## ğŸ‰ Benefits of Local-Only Setup

### ğŸš€ **Faster & Simpler**
- No cloud setup required
- Instant file access
- No network delays
- Simplified deployment

### ğŸ”’ **More Private & Secure**
- Data never leaves your machine
- No cloud provider access
- Complete data ownership
- GDPR/compliance friendly

### ğŸ’° **No Cloud Costs**
- No AWS bills
- No storage fees
- No API call charges
- Free file operations

### ğŸ¯ **Better Development**
- Easier testing
- No API rate limits
- Offline development
- Simplified debugging

---

## ğŸš€ What You Still Get

### âœ… **Complete AutoML Pipeline**
- AI-powered data analysis
- Smart preprocessing code generation
- Multi-model training (XGBoost, RF, DT, NB)
- Real-time progress tracking
- Performance comparison dashboard
- Model download and export

### âœ… **Enterprise Features**
- Secure sandbox execution (E2B)
- Professional UI (Apple design)
- Comprehensive error handling
- Progress tracking and logging
- File management and cleanup

### âœ… **Production Ready**
- Docker containerization
- Health check endpoints
- Storage monitoring
- Performance metrics
- Error reporting

---

## ğŸ Quick Start (3 Steps)

1. **Configure API Keys** (Claude + E2B only)
2. **Start Backend**: `cd backend && python run.py`
3. **Start Frontend**: `cd frontend && npm run dev`

**That's it!** No AWS account, no S3 buckets, no IAM setup needed! ğŸ‰

---

*Your ML pipeline is now 100% local with enterprise-grade features and zero cloud dependencies!*